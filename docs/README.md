# Data Quality Research for African Language MT

Automated detection of data quality errors in African language machine translation using model explainability techniques.

## ğŸ“– Overview

This project analyzes the **AfriDocMT dataset** (Masakhane's African Document-level MT corpus) to identify various types of translation errors using:
- Attention mechanism analysis
- Gradient-based attribution
- Heuristic error detection

**Supported Languages**: Amharic, Hausa, Swahili, Yoruba, Zulu  
**Domains**: Health, Technology  
**Model**: NLLB-200-distilled-600M

## ğŸš€ Quick Start

### Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Running Experiments

**Option 1: Single config/language pair**
```bash
python run_experiments.py --config health --lang sw
```

**Option 2: Sentence-level only (uses local CSV data)**
```bash
python run_experiments.py --sentence-only
```

**Option 3: Full experiment suite** (requires HuggingFace dataset download)
```bash
python run_experiments.py --all
```

### Custom Settings

```bash
python run_experiments.py \
    --config doc_health_10 \
    --lang yo \
    --max-samples 1000 \
    --output-dir my_results
```

## ğŸ“ Project Structure

```
Data Quality Research/
â”œâ”€â”€ config.py                    # Configuration management
â”œâ”€â”€ utils.py                     # Utility functions
â”œâ”€â”€ error_detector.py            # Error detection logic
â”œâ”€â”€ run_experiments.py           # Main experiment runner
â”œâ”€â”€ sentence_level_error.py      # Original framework (multi-task)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â”‚
â”œâ”€â”€ Health/                      # Healthcare domain sentence data
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ dev.csv
â”‚   â””â”€â”€ test.csv
â”‚
â””â”€â”€ Tech/                        # Technology domain sentence data
    â”œâ”€â”€ train.csv
    â”œâ”€â”€ dev.csv
    â””â”€â”€ test.csv
```

## ğŸ” Error Types Detected

1. **OMISSION**: Translation significantly shorter than reference
2. **REPETITION**: Duplicate tokens in output
3. **TERMINOLOGY_DRIFT**: Inconsistent term translation within document
4. **LOW_CONFIDENCE**: Model uncertainty (low log probability)
5. **HIGH_CONFIDENCE_ERROR**: High confidence but poor quality

## âš™ï¸ Configuration

Edit `config.py` to customize:
- Model selection and max length
- Error detection thresholds
- Output settings
- Dataset configurations

### Key Thresholds

```python
omission_threshold = 0.7           # <70% length triggers omission
low_confidence_threshold = -6.0    # Log prob threshold
high_conf_error_similarity = 0.5   # Similarity threshold
terminology_drift_threshold = 0.2  # 20% inconsistency
```

## ğŸ“Š Output Format

Results are saved to `results_complete/` (or custom dir):

```
results_complete/
â”œâ”€â”€ master_summary.json          # Overall statistics
â”œâ”€â”€ experiment.log               # Detailed logs
â”‚
â””â”€â”€ [config_name]/
    â””â”€â”€ [language]/
        â”œâ”€â”€ case_studies.json    # Detailed error cases with explainability
        â””â”€â”€ summary.json         # Error counts
```

### Case Study Format

Each error case includes:
- Source and reference texts
- Generated hypothesis
- Error types detected
- Token-level gradient attribution
- Cross-attention weights
- Confidence scores

## ğŸ§ª GPU Acceleration

The code automatically uses GPU if available:

```python
# In config.py
device = "cuda"  # Auto-falls back to "cpu" if unavailable
```

For multi-GPU systems, set:
```bash
CUDA_VISIBLE_DEVICES=0 python run_experiments.py --all
```

## ğŸ“ Dataset Information

**Source**: [masakhane/AfriDocMT](https://huggingface.co/datasets/masakhane/AfriDocMT)

**Available Configurations**:
- **Sentence-level**: `tech`, `health` (available locally as CSVs)
- **Document-level**: `doc_tech`, `doc_health`, `doc_tech_5/10/25`, `doc_health_5/10/25`

### Downloading Full Dataset

Document-level configs require HuggingFace download:

```python
from datasets import load_dataset

# Download specific config
dataset = load_dataset("masakhane/AfriDocMT", "doc_health_10")

# Or in CLI (automatic on first run)
python run_experiments.py --config doc_health_10 --lang sw
```

## ğŸ”¬ Advanced Usage

### Custom Error Detector

```python
from error_detector import MTErrorDetector

detector = MTErrorDetector(
    omission_threshold=0.6,        # More sensitive
    low_conf_threshold=-5.0,       # Stricter
    terminology_drift_threshold=0.15
)
```

### Programmatic Access

```python
from run_experiments import AfriDocMTExperiment
from config import experiment_config

# Customize config
experiment_config.max_samples = 1000
experiment_config.verbose = True

# Run experiment
exp = AfriDocMTExperiment()
summary = exp.run_single_config("health", "sw")
print(summary)
```

## ğŸ“š Reference

Based on research from:
- **Paper**: "AFRIDOC-MT: Document-level MT Corpus for African Languages" (2501.06374v2.pdf)
- **Dataset**: [Masakhane AfriDocMT](https://huggingface.co/datasets/masakhane/AfriDocMT)
- **Model**: [NLLB-200](https://huggingface.co/facebook/nllb-200-distilled-600M)

## ğŸ› ï¸ Troubleshooting

### Out of Memory (GPU)
- Reduce `max_samples` or `max_length` in config
- Use smaller batch size (currently 1)
- Fall back to CPU: `device = "cpu"` in config

### Dataset Not Found
```bash
# Download specific config
python -c "from datasets import load_dataset; load_dataset('masakhane/AfriDocMT', 'health')"
```

### Import Errors
```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

## ğŸ“„ License

See project license file.

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Additional error detection heuristics
- Support for more languages
- Visualization tools for attention/gradients
- Statistical significance testing
- Human validation interface

## ğŸ“§ Contact

For questions about the research or code, please open an issue.
